import requests
import json
import numpy as np
import gradio as gr
from pymilvus import connections, Collection
from sentence_transformers import SentenceTransformer
import hashlib

# é…ç½®å‚æ•°
API_URL = "http://127.0.0.1:1234/v1/chat/completions"
EMBEDDING_MODEL = "paraphrase-MiniLM-L6-v2"
# MILVUS_COLLECTION = "doc_chunks_collection"
MILVUS_COLLECTION = "documents_collection"
TOP_K = 5  # æ£€ç´¢æ•°é‡
SIMILARITY_THRESHOLD = 0.5  # ç›¸ä¼¼åº¦é˜ˆå€¼

# åˆå§‹åŒ–Milvusè¿æ¥
connections.connect(alias="default", host='localhost', port='19530')
collection = Collection(MILVUS_COLLECTION)
collection.load()

# åˆå§‹åŒ–ç¼–ç æ¨¡å‹
encoder = SentenceTransformer(EMBEDDING_MODEL)


def semantic_search(query, top_k=5):
    """è¯­ä¹‰æ£€ç´¢å‡½æ•°"""
    query_embedding = encoder.encode(query).tolist()

    search_params = {
        "metric_type": "L2",
        "params": {"ef": 64}
    }

    results = collection.search(
        data=[query_embedding],
        anns_field="embedding",
        param=search_params,
        limit=top_k,
        output_fields=["chunk_text", "document_id"]
    )

    formatted_results = []
    for hits in results:
        for hit in hits:
            # è·å–å­—æ®µçš„æ­£ç¡®æ–¹å¼
            chunk_text = hit.entity.chunk_text
            doc_id = hit.entity.document_id
            chunk_type = hit.entity.chunk_type

            if hit.distance < SIMILARITY_THRESHOLD:
                continue

            formatted_results.append({
                "score": 1 - hit.distance,
                "text": chunk_text,
                "doc_id": doc_id,
                "type": chunk_type
            })

    return sorted(formatted_results, key=lambda x: x["score"], reverse=True)


def build_prompt(query, context):
    """æç¤ºæ„å»ºå‡½æ•°"""
    context_str = "\n".join([f"[doc#{doc['doc_id']}] {doc['text']}" for doc in context])
    return f"Answer with a single noun (not a sentence) in â‰¤5 words, English, based on:\n{context_str}\nQuestion: {query}"


def format_retrieval_results(results):
    """ä¼˜åŒ–ç»“æœæ˜¾ç¤ºæ ¼å¼ï¼Œåªä¿ç•™æ–‡æ¡£IDå’Œå†…å®¹ç‰‡æ®µ"""
    return [[
        doc["doc_id"],
        doc["text"][:150] + "..." if len(doc["text"]) > 150 else doc["text"]
    ] for doc in results]


def rag_generation(query, history):
    """å¸¦è¶…æ—¶å¤„ç†çš„å¢å¼ºæµç¨‹"""
    try:
        # 1. æ£€ç´¢ç›¸å…³æ®µè½
        search_results = semantic_search(query, TOP_K)

        # 2. æ„å»ºå¢å¼ºæç¤º
        prompt = build_prompt(query, search_results[:3])  # å–å‰ä¸‰ç›¸å…³

        # 3. æµå¼ç”Ÿæˆ
        response = requests.post(
            API_URL,
            headers={"Content-Type": "application/json"},
            json={
                "messages": [{"role": "user", "content": prompt}],
                "model": "default",
                "temperature": 0.5,
                "stream": True
            },
            stream=True,
            timeout=15  # ç¼©çŸ­è¶…æ—¶æ—¶é—´
        )
        response.raise_for_status()

        full_response = ""
        for chunk in response.iter_lines():
            if chunk:
                decoded = chunk.decode().lstrip('data: ').strip()
                if decoded == "[DONE]":
                    break
                try:
                    data = json.loads(decoded)
                    delta = data['choices'][0]['delta'].get('content', '')
                    full_response += delta
                    yield full_response, search_results
                except:
                    continue
    except Exception as e:
        yield f"è¯·æ±‚å¤±è´¥ï¼š{str(e)}", []


# åˆ›å»ºå¢å¼ºç•Œé¢
with gr.Blocks(title="æ™ºèƒ½æ–‡æ¡£åŠ©æ‰‹", theme="soft") as demo:
    gr.Markdown("## ğŸ“š æ™ºèƒ½æ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼ˆåŸºäºMilvusï¼‰")

    with gr.Row():
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(height=500, bubble_full_width=False)
            query_input = gr.Textbox(label="è¯·è¾“å…¥é—®é¢˜", lines=2)

        with gr.Column(scale=2):
            retrieval_display = gr.DataFrame(
                headers=["æ–‡æ¡£ID", "å†…å®¹ç‰‡æ®µ"],
                datatype=["number", "str"],
                interactive=False,
                wrap=True,
                column_widths=["20%", "80%"]
            )

    with gr.Row():
        submit_btn = gr.Button("æäº¤æŸ¥è¯¢", variant="primary")
        clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯", variant="secondary")


    def process_query(query, history):
        # åˆå§‹åŒ–çŠ¶æ€
        yield history + [[query, "æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£..."]], []

        try:
            # æ‰§è¡ŒRAGæµç¨‹
            generator = rag_generation(query, history)
            final_response = ""
            final_results = []

            for partial_res, results in generator:
                final_response = partial_res
                final_results = results
                yield history + [[query, final_response]], format_retrieval_results(final_results)

            # æœ€ç»ˆæ›´æ–°
            new_history = history + [[query, final_response]]
            yield new_history, format_retrieval_results(final_results)

        except Exception as e:
            error_msg = f"ç³»ç»Ÿé”™è¯¯ï¼š{str(e)}"
            yield history + [[query, error_msg]], []


    # äº¤äº’é€»è¾‘
    query_input.submit(
        process_query,
        [query_input, chatbot],
        [chatbot, retrieval_display]
    )
    submit_btn.click(
        process_query,
        [query_input, chatbot],
        [chatbot, retrieval_display]
    )
    clear_btn.click(lambda: (None, []), None, [chatbot, retrieval_display])

if __name__ == "__main__":
    demo.launch(
        server_name="127.0.0.1",
    )
