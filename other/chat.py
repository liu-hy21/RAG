import requests
import json
import numpy as np
import gradio as gr
from sentence_transformers import SentenceTransformer
from faiss import IndexFlatIP
from vectorDB import get_document_vector

# é…ç½®å‚æ•°
API_URL = "http://127.0.0.1:1234/v1/chat/completions"
EMBEDDING_MODEL = "paraphrase-multilingual-MiniLM-L12-v2"  # å¤šè¯­è¨€å°åž‹æ¨¡åž‹
VECTOR_DIM = 384  # ä¸Žæ¨¡åž‹ç»´åº¦åŒ¹é…
TOP_K = 3  # æ£€ç´¢æ•°é‡

# ç¤ºä¾‹å‘é‡æ•°æ®åº“ï¼ˆå®žé™…åº”ä»Žæ•°æ®åº“åŠ è½½ï¼‰
documents = get_document_vector()

# åˆå§‹åŒ–æ¨¡åž‹å’Œç´¢å¼•
encoder = SentenceTransformer(EMBEDDING_MODEL)
index = IndexFlatIP(VECTOR_DIM)
doc_embeddings = np.stack([doc["embedding"] for doc in documents])
index.add(doc_embeddings)


def semantic_search(query, top_k=3):
    """è¯­ä¹‰å‘é‡æ£€ç´¢"""
    # ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_embedding = encoder.encode(query, convert_to_tensor=True).cpu().numpy()
    query_embedding = query_embedding.astype('float32').reshape(1, -1)

    # ç›¸ä¼¼åº¦æœç´¢
    distances, indices = index.search(query_embedding, top_k)

    # ç»„åˆæ£€ç´¢ç»“æžœ
    results = []
    for idx, score in zip(indices[0], distances[0]):
        if idx >= 0:  # FAISSå¯èƒ½è¿”å›ž-1
            doc = documents[idx]
            results.append({
                "score": float(score),
                "document_text": doc["document_text"],
                "document_id": doc["document_id"]
            })
    return sorted(results, key=lambda x: x["score"], reverse=True)


def build_prompt(query, context):
    """æž„å»ºå¢žå¼ºæç¤º"""
    context_str = "\n".join([f"[å‚è€ƒæ–‡æ¡£ {i + 1}] {doc['document_text']}"
                             for i, doc in enumerate(context)])
    return f"""åŸºäºŽä»¥ä¸‹å‚è€ƒæ–‡æ¡£å›žç­”é—®é¢˜ï¼š
{context_str}

é—®é¢˜ï¼š{query}
ç­”æ¡ˆï¼š"""


def rag_generation(query, history):
    """RAGæµç¨‹å¤„ç†"""
    # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
    search_results = semantic_search(query, TOP_K)

    # 2. æž„å»ºæç¤º
    context = [res for res in search_results if res["score"] > 0.5]  # ç›¸ä¼¼åº¦é˜ˆå€¼
    prompt = build_prompt(query, context)

    # 3. æµå¼ç”Ÿæˆ
    try:
        response = requests.post(
            API_URL,
            headers={"Content-Type": "application/json"},
            json={
                "messages": [{"role": "user", "content": prompt}],
                "model": "default",
                "temperature": 0.7,
                "stream": True
            },
            stream=True,
            timeout=30
        )
        response.raise_for_status()

        full_response = ""
        for chunk in response.iter_lines():
            if chunk:
                decoded = chunk.decode().lstrip('data: ').strip()
                if decoded == "[DONE]":
                    break
                try:
                    data = json.loads(decoded)
                    delta = data['choices'][0]['delta'].get('content', '')
                    full_response += delta
                    yield full_response
                except:
                    continue
    except Exception as e:
        yield f"ç”Ÿæˆå¤±è´¥ï¼š{str(e)}"


def format_retrieval_results(results):
    """æ ¼å¼åŒ–æ£€ç´¢ç»“æžœç”¨äºŽè¡¨æ ¼æ˜¾ç¤ºï¼ˆåŽ»é™¤ç›¸ä¼¼åº¦ï¼ŒåŠ é•¿ç‰‡æ®µï¼‰"""
    return [[
        doc["document_id"],
        doc["document_text"][:250] + "..." if len(doc["document_text"]) > 250 else doc["document_text"]
    ] for doc in results]


# åˆ›å»ºå¢žå¼ºç‰ˆç•Œé¢
with gr.Blocks(title="RAGå¯¹è¯ç³»ç»Ÿ", theme="soft") as demo:
    gr.Markdown("## ðŸ§  æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼ˆæ£€ç´¢å¢žå¼ºç‰ˆï¼‰")

    with gr.Row():
        with gr.Column(scale=2):
            chatbot = gr.Chatbot(height=500)
            msg = gr.Textbox(label="è¾“å…¥é—®é¢˜")
        # ä¿®æ”¹ç•Œé¢éƒ¨åˆ†
        with gr.Column(scale=1):
            retrieval_output = gr.DataFrame(
                label="ðŸ“š ç›¸å…³æ–‡æ¡£",
                headers=["æ–‡æ¡£ID", "å†…å®¹ç‰‡æ®µ"],
                datatype=["number", "str"],
                interactive=False,
                wrap=True,
                height=400,
                column_widths=["20%", "80%"]  # è°ƒæ•´åˆ—å®½æ¯”ä¾‹
            )

    with gr.Row():
        submit_btn = gr.Button("æäº¤", variant="primary")
        clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯")


    def respond(message, chat_history):
        # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
        yield chat_history + [[message, ""]], [["æ£€ç´¢ä¸­...", "", ""]]

        # æ‰§è¡ŒRAGæµç¨‹
        search_results = semantic_search(message, TOP_K)
        context = [res for res in search_results if res["score"] > 0.5]
        formatted_results = format_retrieval_results(context)

        generator = rag_generation(message, chat_history)
        response = ""
        for partial_res in generator:
            response = partial_res
            yield chat_history + [[message, response]], formatted_results

        # æœ€ç»ˆæ›´æ–°
        new_history = chat_history + [[message, response]]
        yield new_history, formatted_results


    # äº¤äº’é€»è¾‘
    msg.submit(
        respond,
        [msg, chatbot],
        [chatbot, retrieval_output],
        show_progress="hidden"
    )
    submit_btn.click(
        respond,
        [msg, chatbot],
        [chatbot, retrieval_output],
        show_progress="hidden"
    )
    clear_btn.click(lambda: None, None, chatbot, queue=False)

demo.launch(server_name="127.0.0.1", share=False)
